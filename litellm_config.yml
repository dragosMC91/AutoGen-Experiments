model_list:

  - model_name: ollama/codellama
    litellm_params:
      model: "ollama/codellama:34b"

  - model_name: mistral/mistral-medium
    litellm_params:
      model: mistral/mistral-medium-latest
      api_key: os.environ/MISTRAL_API_KEY
      api_base: https://api.mistral.ai/v1

  - model_name: openai/gpt-4-turbo-2024-04-09
    litellm_params:
      model: openai/gpt-4-turbo-2024-04-09
      api_key: os.environ/OPENAI_API_KEY
      api_base: https://api.openai.com/v1

  - model_name: openai/o3-mini
    litellm_params:
      model: o3-mini
      api_key: os.environ/OPENAI_API_KEY
      api_base: https://api.openai.com/v1
      reasoning_effort: high

  - model_name: openai/o1-preview
    litellm_params:
      model: o1-preview
      api_key: os.environ/OPENAI_API_KEY
      api_base: https://api.openai.com/v1

  - model_name: openai/gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      api_base: https://api.openai.com/v1

  - model_name: openai/gpt-4o-2024-11-20
    litellm_params:
      model: gpt-4o-2024-11-20
      api_key: os.environ/OPENAI_API_KEY

  - model_name: openai/gpt-4o-mini
    litellm_params:
      model: gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
      api_base: https://api.openai.com/v1

  - model_name: openai/o1-preview
    litellm_params:
      model: openai/o1-preview
      api_key: os.environ/OPENAI_API_KEY
      api_base: https://api.openai.com/v1

  - model_name: openai/gpt-3.5-turbo-0125
    litellm_params:
      model: openai/gpt-3.5-turbo-0125
      api_key: os.environ/OPENAI_API_KEY
      api_base: https://api.openai.com/v1

  - model_name: openai/gpt-3.5-turbo
    litellm_params:
      model: openai/gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY
      api_base: https://api.openai.com/v1

  - model_name: openai/dall-e-3
    litellm_params:
      model: openai/dall-e-3
      api_key: os.environ/OPENAI_API_KEY
      api_base: https://api.openai.com/v1

  - model_name: mistral/mistral-large
    litellm_params:
      model: mistral/mistral-large-latest
      api_key: os.environ/MISTRAL_API_KEY
      api_base: https://api.mistral.ai/v1

  - model_name: anthropic/claude-3-opus
    litellm_params:
      model: claude-3-opus-20240229
      api_base: https://api.anthropic.com/v1/messages
      api_key: os.environ/ANTHROPIC_API_KEY
      # explicit max_tokens required because a 256 default is being set otherwise
      max_tokens: 4096

  - model_name: anthropic/claude-3.5-sonnet
    litellm_params:
      model: claude-3-5-sonnet-20241022
      api_base: https://api.anthropic.com/v1/messages
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 4096

  - model_name: anthropic/claude-3.7-sonnet
    litellm_params:
      model: claude-3-7-sonnet-20250219
      api_base: https://api.anthropic.com/v1/messages
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 4096

  - model_name: anthropic/claude-3.5-haiku
    litellm_params:
      model: claude-3-5-haiku-20241022
      api_base: https://api.anthropic.com/v1/messages
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 4096

  - model_name: deepseek/deepseek-v3
    litellm_params:
      model: deepseek/deepseek-chat
      api_base: https://api.deepseek.com
      api_key: os.environ/DEEPSEEK_API_KEY
      max_tokens: 4096

  - model_name: deepseek/deepseek-r1
    litellm_params:
      model: deepseek/deepseek-reasoner
      api_base: https://api.deepseek.com
      api_key: os.environ/DEEPSEEK_API_KEY
      max_tokens: 4096

  - model_name: openrouter/claude-3.7-thinking
    litellm_params:
      model: openrouter/anthropic/claude-3.7-sonnet:thinking
      # api_base: https://api.anthropic.com/v1/messages
      api_key: os.environ/OPENROUTER_API_KEY
      max_tokens: 4096

  - model_name: openrouter/gemini-2.0-flash
    litellm_params:
      model: openrouter/google/gemini-2.0-flash-001
      # api_base: https://openrouter.ai/api/v1/chat/completions
      api_key: os.environ/OPENROUTER_API_KEY
      max_tokens: 4096

  - model_name: google/gemini-2.0-flash
    litellm_params:
      model: gemini/gemini-2.0-flash
      api_key: os.environ/GEMINI_API_KEY
      max_tokens: 4096

  - model_name: google/gemini-2.5-pro-exp-03-25
    litellm_params:
      model: gemini/gemini-2.5-pro-exp-03-25
      api_key: os.environ/GEMINI_API_KEY
      max_tokens: 4096

  - model_name: openrouter/llama-3.1-sonar-large-online
    litellm_params:
      model: openrouter/perplexity/llama-3.1-sonar-large-128k-online
      # api_base: https://openrouter.ai/api/v1/chat/completions
      api_key: os.environ/OPENROUTER_API_KEY
      max_tokens: 4096

  - model_name: openrouter/sonar-r1
    litellm_params:
      model: openrouter/perplexity/sonar-reasoning
      # api_base: https://openrouter.ai/api/v1/chat/completions
      api_key: os.environ/OPENROUTER_API_KEY
      max_tokens: 4096

  - model_name: openrouter/deepseek-v3
    litellm_params:
      model: openrouter/deepseek/deepseek-chat
      api_key: os.environ/OPENROUTER_API_KEY
      max_tokens: 4096

  - model_name: openrouter/deepseek-r1
    litellm_params:
      model: openrouter/deepseek/deepseek-r1
      api_key: os.environ/OPENROUTER_API_KEY
      max_tokens: 4096

litellm_settings:
  drop_params: True
  stream: False

general_settings: 
  master_key: os.environ/LITELLM_MASTER_KEY
  database_url: os.environ/DATABASE_URL
  database_connection_pool_limit: 100
  database_connection_timeout: 60